{
  "engines": [
    {
      "engine_id": "AUDIO.INGEST.LOCAL_V1",
      "label": "Local/GCS inbox sync runner",
      "category": "ingest",
      "source_pipeline": ["bot-better-know"],
      "primary_script": "engines/bot-better-know/pipeline/ingest.py",
      "entry_points": ["main", "sh"],
      "inputs": ["GCS inbox bucket or local upload directory"],
      "outputs": ["Local working dirs with inbox/segments/asr/aligned/datasets/model populated"],
      "oss_dependencies": ["gsutil", "python"],
      "notes": "Orchestrator entrypoint that currently syncs from GCS and runs the full grime pipeline; can be isolated for ingest/staging."
    },
    {
      "engine_id": "AUDIO.SEGMENT.FFMPEG_V1",
      "label": "FFmpeg audio segmenter",
      "category": "audio",
      "source_pipeline": ["bot-better-know"],
      "primary_script": "engines/bot-better-know/pipeline/01_segment_ffmpeg.py",
      "entry_points": ["main", "process_file"],
      "inputs": ["Raw audio/video file"],
      "outputs": ["Mono mp3 segments (~90 seconds)"],
      "oss_dependencies": ["ffmpeg"],
      "notes": "Extracts mono mp3 and chunks long uploads for downstream ASR."
    },
    {
      "engine_id": "AUDIO.ASR.WHISPER_V1",
      "label": "Whisper ASR (faster-whisper)",
      "category": "asr",
      "source_pipeline": ["bot-better-know"],
      "primary_script": "engines/bot-better-know/pipeline/02_whisper_asr.py",
      "entry_points": ["main", "transcribe_file"],
      "inputs": ["Segmented mp3 audio"],
      "outputs": ["Whisper JSON with segments and word timestamps"],
      "oss_dependencies": ["faster-whisper", "ctranslate2"],
      "notes": "CPU-friendly Whisper transcription with per-word timing for alignment."
    },
    {
      "engine_id": "TEXT.NORMALISE.SLANG_V1",
      "label": "Slang-preserving normalizer",
      "category": "text",
      "source_pipeline": ["bot-better-know"],
      "primary_script": "engines/bot-better-know/pipeline/02b_normalize_slang.py",
      "entry_points": ["main", "SlangNormalizer.normalize_payload", "write_norm_file"],
      "inputs": ["Whisper JSON payload"],
      "outputs": ["Normalized JSON (.norm) with slang-aware tokens"],
      "oss_dependencies": ["python"],
      "notes": "Uses slang lexicon to normalize grime variants without censoring profanity."
    },
    {
      "engine_id": "AUDIO.BEAT.FEATURES_V1",
      "label": "Beat/tempo analyzer",
      "category": "audio-analysis",
      "source_pipeline": ["bot-better-know"],
      "primary_script": "engines/bot-better-know/pipeline/03_beat_features.py",
      "entry_points": ["main", "process_file"],
      "inputs": ["Segmented mp3 audio"],
      "outputs": ["Meta JSON with bpm, downbeats, 16th grid"],
      "oss_dependencies": ["librosa"],
      "notes": "Computes tempo, downbeats, and 16th-note grid for alignment/tagging."
    },
    {
      "engine_id": "ALIGN.AUDIO_TEXT.BARS_V1",
      "label": "Word-to-bar aligner",
      "category": "alignment",
      "source_pipeline": ["bot-better-know"],
      "primary_script": "engines/bot-better-know/pipeline/04_align_words.py",
      "entry_points": ["main", "prefer_norm", "syllable_count"],
      "inputs": ["ASR JSON (optionally normalized)", "Beat metadata JSON"],
      "outputs": ["Bar JSON with text, syllable counts, stress slots"],
      "oss_dependencies": ["python"],
      "notes": "Maps per-word timings onto 16-slot bars using beat grid and syllable heuristics."
    },
    {
      "engine_id": "TAG.FLOW.AUTO_V1",
      "label": "Rule-based flow tagger",
      "category": "tagging",
      "source_pipeline": ["bot-better-know"],
      "primary_script": "engines/bot-better-know/pipeline/05_auto_tag_flow.py",
      "entry_points": ["main", "annotate_file", "predict_flow"],
      "inputs": ["Bar JSON"],
      "outputs": ["Bar JSON with flow_pred fields", "Flow CSV summaries"],
      "oss_dependencies": ["python"],
      "notes": "Heuristic flow classifier over pairs of bars; annotates JSON and emits CSV."
    },
    {
      "engine_id": "DATASET.PACK.JSONL_V1",
      "label": "Bars to JSONL packer",
      "category": "dataset",
      "source_pipeline": ["bot-better-know"],
      "primary_script": "engines/bot-better-know/pipeline/06_pack_jsonl.py",
      "entry_points": ["main", "pack_file"],
      "inputs": ["Bar JSON", "Optional flow CSV"],
      "outputs": ["train.jsonl", "val.jsonl"],
      "oss_dependencies": ["python"],
      "notes": "Packs aligned bars into instruction-style train/val splits with rhyme/flow metadata."
    },
    {
      "engine_id": "TRAIN.LORA.LOCAL_V1",
      "label": "LoRA metadata trainer placeholder",
      "category": "training",
      "source_pipeline": ["bot-better-know"],
      "primary_script": "engines/bot-better-know/pipeline/07_train_lora.py",
      "entry_points": ["main", "count_lines"],
      "inputs": ["train.jsonl", "val.jsonl"],
      "outputs": ["adapter_config.json metadata stub"],
      "oss_dependencies": ["python"],
      "notes": "Records counts and base model info; replace with real adapter training when ready."
    },
    {
      "engine_id": "AUDIO.PREPROCESS.BASIC_CLEAN_V1",
      "id": "AUDIO.PREPROCESS.BASIC_CLEAN_V1",
      "kind": "atomic",
      "domain": "audio",
      "label": "Basic audio cleaner",
      "category": "audio",
      "source_pipeline": [],
      "primary_script": "",
      "entry_points": [],
      "inputs": ["raw audio files"],
      "outputs": ["cleaned audio ready for segmentation/ASR"],
      "oss_dependencies": ["ffmpeg", "sox"],
      "description": "Lightweight denoise/normalize pass to improve downstream ASR quality.",
      "notes": "Spec-only entry; implement as reusable preprocessing step."
    },
    {
      "engine_id": "VIDEO.INGEST.FRAME_GRAB_V1",
      "id": "VIDEO.INGEST.FRAME_GRAB_V1",
      "kind": "atomic",
      "domain": "video",
      "label": "Frame grabber",
      "category": "video",
      "source_pipeline": [],
      "primary_script": "",
      "entry_points": [],
      "inputs": ["video files", "mode", "frame_every_n_seconds", "max_frames", "timestamps_ms"],
      "outputs": ["still frames (jpg/png)", "frame index listing {timestamp_ms, frame_uri}", "basic video metadata"],
      "oss_dependencies": ["ffmpeg"],
      "description": "Extracts frames from video in either auto interval mode or manual timeline-driven mode.",
      "notes": "Spec-only entry; useful for multimodal dataset prep. Manual mode is deterministic and only returns requested timestamps.",
      "modes": {
        "auto": {
          "inputs": ["video_uri", "frame_every_n_seconds", "max_frames"],
          "outputs": ["list of {timestamp_ms, frame_uri}", "basic meta"],
          "behavior": "Fixed-interval grabs for thumbnails/dataset sampling."
        },
        "manual": {
          "inputs": ["video_uri", "timestamps_ms[]"],
          "outputs": ["list of {timestamp_ms, frame_uri}", "basic meta"],
          "behavior": "Frame-accurate grabs exactly at provided timestamps; no heuristic selection."
        }
      }
    },
    {
      "engine_id": "TEXT.CLEAN.ASR_PUNCT_CASE_V1",
      "id": "TEXT.CLEAN.ASR_PUNCT_CASE_V1",
      "kind": "atomic",
      "domain": "text",
      "label": "ASR punctuation + casing cleaner",
      "category": "text",
      "source_pipeline": [],
      "primary_script": "",
      "entry_points": [],
      "inputs": ["raw ASR transcript text/JSON"],
      "outputs": ["punctuated and cased transcript text/JSON"],
      "oss_dependencies": ["python"],
      "description": "Restores punctuation and casing to ASR outputs for readability and downstream NLP.",
      "notes": "Spec-only entry; can wrap lightweight NLP/regex or model-based punctuators."
    },
    {
      "engine_id": "AUDIO.INGEST.LOCAL_FILE_V1",
      "id": "AUDIO.INGEST.LOCAL_FILE_V1",
      "kind": "atomic",
      "domain": "audio",
      "label": "Local file ingestor",
      "category": "ingest",
      "source_pipeline": [],
      "primary_script": "",
      "entry_points": [],
      "inputs": ["local audio/video file paths"],
      "outputs": ["staged media in working directory structure"],
      "oss_dependencies": ["python"],
      "description": "Stages user-provided local media into a predictable inbox for pipelines.",
      "notes": "Spec-only entry; complements remote pull ingest."
    },
    {
      "engine_id": "AUDIO.INGEST.REMOTE_PULL_V1",
      "id": "AUDIO.INGEST.REMOTE_PULL_V1",
      "kind": "atomic",
      "domain": "audio",
      "label": "Remote media puller",
      "category": "ingest",
      "source_pipeline": [],
      "primary_script": "",
      "entry_points": [],
      "inputs": ["remote URLs or bucket/object references"],
      "outputs": ["downloaded/staged media files"],
      "oss_dependencies": ["curl", "wget", "gsutil"],
      "description": "Fetches remote audio/video into local staging for processing.",
      "notes": "Spec-only entry; decouples acquisition from processing."
    },
    {
      "engine_id": "TRAIN.LORA.PEFT_HF_V1",
      "id": "TRAIN.LORA.PEFT_HF_V1",
      "kind": "atomic",
      "domain": "training",
      "label": "LoRA trainer (PEFT/HF)",
      "category": "training",
      "source_pipeline": [],
      "primary_script": "",
      "entry_points": [],
      "inputs": ["train.jsonl", "val.jsonl", "base model reference", "training config"],
      "outputs": ["LoRA adapter weights", "training metrics/logs"],
      "oss_dependencies": ["pytorch", "transformers", "peft"],
      "description": "Runs LoRA fine-tuning using HuggingFace PEFT for downstream adapters.",
      "notes": "Spec-only entry; replaces metadata-only trainer with real training once implemented."
    }
  ]
}
