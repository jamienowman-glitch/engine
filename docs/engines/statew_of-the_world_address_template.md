State of the World Address

I want u create a reporting mechanism that we can then follow the pattern of for bossman
To point an agent at a template which we have version one below update the template as and when needed with new headings and the template itself then serves as a planning document that at the top has instructions for any agent to read of how to fill-in and then would proceed to section by section fill it in but in Bossman speak technical and especially referencing the concepts where we currently are with them within the repo with direct then references to the files where you can find them underneath but not going to technical in terms of the code or the shapes of json etc

We can then have saved in bossman files a kickoff prompt that will get an agent to read and fill in that document not just plan it. The document can be an .md file called state-of-the-world-address.md

Every time a new state of the world address is filled out by an agent they should create a copy and append it with the date in dd-mm-yy format. To be clear here I want you to create this template with the explanations below of what I'm looking for after which I will then point you or maybe a new agent at it to fill it in.

Surfaces apps Federation's clusters agents

This is the different levels and groupings of agents into cluster clusters into Federation Federation into apps which all sit on the surface which can share then the same Nexus what references do we have to this? It needs to be open-ended that you can add and layer up and if not, what would we need to plan to make sure that this is respected and this needs to be always cards driven for each so that it is non-deterministic which each one is I'm not use the power of the system through manifest and clusters of agents

Tools

For the OS to work everything needs to be wrapped as a tool where agent is appears tools to the layer up clusters appears tools engines appear as tools connectors appear as tools do we have this defined at this point in time? If not what would we need to plan to get there ? This will happen within cards and registries of cards, but we need to have I'm sure something in the back end to make it a reality.

Rootsmanuva

we want to become a service, model, orchestration, infrastructure agnostic what do we currently have set up? And where are the obvious places that we will when the connectors are ready? Actually be able to apply this to?


Selecta Route

we rely on deterministic but not bound by initial set up weightings and where the measurements actually matter and priorities would be able to be changed over time with also than a periodical review by a stack of Llm making it a deterministic pipeline but tuned by situationally aware LLM.


Grounding and hallucinations

Do we have an official way or references but not hardened to stop grounding stop hallucinations and for checking below the surface, whether something has been hallucinated, 3-wise-llm will be one but should not be the only way of doing this. 

Strategy lock

This takes its form in two ways. It's a human in the loop process where it's meant to be the step for confirming the strategy something that can go ahead but they're only after it's been through the kpi, budget, 3-wise-LLM, firearms & budget checks.


Policies & Rules

Nexus the key for informing the system and allowing each agent to take their own view on how to interpret preferences style data but to counteract that on the other side there will be times and certain sets much like firearms. We want to reduce it too as much as possible but rules that each tenant will have that should not be broken these seem and should be enforced in your more standard table format. Big query is the one that comes to mind is this in place if not is Bigg query the best one to use and what path to get there?

3-Wise LLM

Being able to put risky decisions out to either driven by the user or underneath by the system to a cold call but I want to ensure that there's no references a predetermined prompt that might go out and no prior settings like you are an optimist you are a pessimist that's strictly needs to be prohibited here and everything of that type needs to be card based. How do we have it in forced here but also in terms of models Yuste what are the options? How would we be able to change the options and this is something that then also should be using rootsmanuva 

Firearms Licences

Instead of huge allow and to allow lists, we just gate the truly destructive risky behind firearms licenses. Google recently through the ADK allowed agents to be first class users I think it's a word where are we on this? What would need to be changed to get there?

Floors and ceilings

To prevent not just risky and out of scope behaviour KPIs and budgets must be used from the system becoming lazy and only targeting a great KPI by only doing one job that they're going to do really well and hit their KPI target. What do we have in terms of floors and ceilings within the repo to avoid this behaviour?

KPI

At the moment, How would the human be able to use KPI to drive the system and limit the system.

Budgets

How would budget be used as a control method for the system and whether through strategy Lock or firearms or three wise LLM would this be surfaced to the human?

Autonomy

The above are meant to be structures that allow the system to be autonomous and emergent whilst being safe. Are there any gaps in any of these?

Lead the Dance

This is something that I feel might be reference to be interested to know where the reapo but something we need to double down on at the core of the system with the atoms fam concept we are aiming to produce expert level work in which ever Field we point Northstar at. One area we probably hand waved a lot about but maybe not actually distinctly to you but within this system is the idea of lead the Dance.. so I expect it doesn't exist in a formal way within this repo but we do need to work out how we will enforce it and this is a concept that given a strong manifest set up prompt understanding the current state from Nexus which could be zero if it's brand-new user or maybe a user has been using it for years it should be upon the agent or cluster of agents to know and ask what they need to ask from the user to produce great work. I'm pretty sure at this moment this does not exist but if it does where does it and if not What? roots could we follow to get this done?

Atoms Fam: The concept of targeted tokens so we get specialised atomic level control and also as a safety measure so that smaller focused agents have a narrow window to work on whether in the UI able to collaborate with humans in the same space without regenerating a whole piece every time, on the code base where our workflow of doing plans and then implementing them is one such example of it that we will be implementing,

Nexus: distinctly vector spaces ready to be explored by humans through Haze a 3-D first person walk-through a landscape potentially later we may do other ones. I've got an idea for representing a space time but not able to make changes in this. The only way I want changes to be made is through uploading material. And how the currently would you start filling in Nexus what's been created and what is still outstanding?



Forecasting

Tuning: I'm pretty sure this probably only exists within bot better know

The plant final site map which is itself is a version of atoms fam ensuring we have distinct repo

Temperature

Just a map of the current set up of what memory we're mapping to wear and to which services and which ones have not been decided yet I know everything will be google


Meta-pidgen + gossip

The concept that agents will be able to output packets of data in natural language that can be subscribed to by other agents as a decentralised way of sharing success

Blackboards

The temporary spaces that are read and write during sessions

Multi-tenant

How are we enforcing this and how does each tenant get personalisation

Research

What roots exist for research to populate the Nexus from the system site, ideally with teams of agents sorting academic research style books et cetera et cetera

Fireprompt

What references do we have to prompt optimisation? How is it implemented? What is still handwaving and what would need to be hardened? Do you have implemented both subsystem? But also a function that the HITL can call on

MDMAD

This is a new concept that I've just thought of, but just like fire prompt is meant to optimise prompts working with agents creating long running plans such as the ones we've been creating together it is not an easy task but there is methods to doing it to ensure they're safe but get carried out autonomously how could be implement this as a similar system to fire prompt making it easier for non-specialists to use the power of agents using all of our safety measures but let the system do the lead the dance on it



Orchestration

This will be another Rootsmanuva area and what are we set up or references? Do we have set up for our first options in terms of orchestration and what exists so far from deterministic hybrid and pure LLM orchestration

Agent memory

What do we currently have so that agents can remember and carry context between conversation conversations?

Maybes

The human scratch pad how does it work? Where are we with it? And what's it set up to behaviour like?

Haze

This is the 3-D vector space exploration tool how far are we to making this in reality from the backend point of view and what would it take us on the front end to actually have this as a working file explorer but optimised for the modern vector space.


Engines

So for me, this is the process that we've been instead of relying on third-party API I've realised it's almost easier to start our own open source projects so that we have proprietary services such as 3-D and I can't think what we did yet but I want to get a state of plate on this


Emergence

Considering everything we've put in place the aim here is to create a safe system but that does not stay full opportunity for emergent behaviour. Is there anything that I've missed that contribute to this or are there any factors that need to be considered that may be stifling this?

Quantum

Once the connectors are ready and then we have the agents defined through manifest what we have ready on quantum and then how would we envision considering the current system? We have actually identifying data sets to test with quantum?

Cards

The design of the system is focused on natural language and the power of the manifest or prompt that you give to agents to change the behaviour of the system and no predetermined prompts. How true to this? If we stayed if not please give me exact details on where we may have strayed.

Personalisation

So this is going to be core in the actual cards that reload but is there any reference to it within the repo that every one will not only get a manifest for their role but also for how they communicate with the human not how they produce the work it's different but to make them memorable and distinctly different from each other



Audit/logs/tuning/de-bugging

With all of these, they are very similar in nature. How are we making? Sure that the system is ready to go through an audit? What is logged? What then do we add on top to make it being able to be tracking data for tuning from Day One and what through that do we actually record the specific for the bugging?

How are we recording orchestration patterns and being able to present in a place to be able to change inspect the cards driving agents and then being able to simulate a new set up to check quickly? What is actually going to be one of the bigger challenges of this and determines of the qualitative work that we produce.

Chat

Chat will be central to every part of this. Where are we in terms of transmitting through SSE tokens so that collaborative canvases and statuses such as thinking planning are real statuses from the back end rooted through different models but still would need to be done on this and where do we have?

Below is just one view chat and I'm still the final parts of it but I know this is the Northstar we need to get to so how far are we off this ? What's the brief steps we need to get there?


⸻

Realtime transport for chat + canvas: WebSockets and SSE

For anything interactive in the system – especially the “WhatsApp-style” chat talking to agents, and the shared canvas / Photoshop-style UI where humans and agents both make changes – we standardise on two realtime channels:
	1.	WebSockets – two-way control + chat
WebSockets are the primary pipe for two-way communication between the client and the orchestrator:
	•	Carry chat messages between human ↔ agent(s).
	•	Carry commands from chat to the canvas, e.g.:
	•	“Update this CTA token.”
	•	“Ask the colour agent to adjust this button.”
	•	“Tell the layout agent to move this block.”
	•	Carry notifications back from the orchestrator that something has been accepted, queued, or rejected.
Conceptually: WebSockets are the control channel. They’re where intent and instructions flow in both directions, in realtime.
	2.	Server-Sent Events (SSE) – one-way streaming of state & “thinking”
SSE is used as a one-way stream from the orchestrator to the client for anything that looks like:
	•	Continuous progress / “thinking” / “working” updates:
	•	“Agent X is analysing…”
	•	“Preparing preview…”
	•	“Applying change set…”
	•	Streaming canvas updates while an agent is working on the backend:
	•	incremental changes to the collaborative UI,
	•	token-level updates as agents apply edits to their allowed tokens,
	•	status of longer operations (e.g. heavy optimisation passes).
	•	Any other firehose-style status feed where the client just needs to listen, not talk back on that same channel.
Conceptually: SSE is the state stream. When agents are busy on the canvas or the system is mid-operation, SSE is how the UI sees that work unfolding in realtime.
	3.	How they fit together
	•	The human talks in chat → messages go over WebSockets.
	•	The orchestrator routes those messages to the right specialist agents, each only allowed to touch its own set of tokens on the canvas.
	•	As agents work:
	•	their status and incremental results are pushed down over SSE,
	•	so the human sees “thinking / working / updating” without having to poll.
	•	The human can keep chatting, adjusting instructions, or making direct canvas edits, and those intents continue to move over WebSockets.

This split gives us:
	•	Low-latency, two-way control and conversation via WebSockets.
	•	Smooth, one-way visual and status streaming via SSE whenever the system or agents are “doing work” on the canvas or preparing responses.

RL & RLHA

I have only just and on purpose because I work by using my imagination and also experience in corporate my small businesses business and 25+ years of following AI to come up with the current system we have. I find that reading anything during it may actually predetermine our direction. Similar to the system that I'm trying to design. I don't like to be predetermined. I have now started to look back into questions like how the deepmind do what they do. And I have as often through this project realised not by accident but by my boss Man way of driving it we have actually arrived at a system is ready and set up for RL & RLHA through strategy Lock is the RLHA.

 RL is KPI’s and we do have some but potentially could exploit more ways of agents communicating this through the one way gossip.  Is there anything we can do to harden this. And is there anything we can do to prevent gaming the system by the agents. 


